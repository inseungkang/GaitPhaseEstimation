{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import *\n",
    "from model_training import *\n",
    "import glob\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from os import path\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pd.read_csv('data/columns.txt', header=None)\n",
    "columns_list = columns.transpose().values.tolist()[0]\n",
    "\n",
    "sensors = ['lJPos', 'rJPos', 'lJVel',\n",
    "           'rJVel', 'gyroX', 'gyroY', 'gyroZ', 'accX',\n",
    "           'accY', 'accZ']\n",
    "\n",
    "mode_pool = ['L0R0']\n",
    "trial_pool = [1, 2, 3, 4, 5]\n",
    "data_all = []\n",
    "\n",
    "data_dir = 'data/'\n",
    "for mode in mode_pool:\n",
    "    for trial in trial_pool:\n",
    "        file_path = data_dir+'log_'+str(mode)+'_'+str(trial)+'.txt'\n",
    "        if path.exists(file_path) == 1:\n",
    "            for read_path in glob.glob(file_path):\n",
    "                data = pd.read_csv(read_path, sep=\" \", header=None)\n",
    "                data = data.iloc[:,0:15]\n",
    "                data.columns = columns_list\n",
    "                data = data[sensors]\n",
    "                data_all.append(data)\n",
    "data_list = label_data(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN Model\n",
    "hyperparam_space = {\n",
    "    'window_size': [30],\n",
    "    'model': 'cnn',\n",
    "    'cnn': {\n",
    "      'kernel_size': [20],\n",
    "      'activation': ['relu']\n",
    "    },\n",
    "    'dense': {\n",
    "        'activation': ['tanh']\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'loss': ['mean_absolute_error'],\n",
    "        'optimizer': ['adam']\n",
    "    },\n",
    "    'training': {\n",
    "        'epochs': [10],\n",
    "        'batch_size': [128]\n",
    "    }\n",
    "}\n",
    "hyperparameter_configs = get_model_configs(hyperparam_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20942, 30, 10)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 30, 10)            21        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 11, 10)            2010      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1, 10)             1110      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 44        \n",
      "=================================================================\n",
      "Total params: 3,185\n",
      "Trainable params: 3,164\n",
      "Non-trainable params: 21\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3180 - val_loss: 0.3479\n",
      "Epoch 2/10\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.1966 - val_loss: 0.3193\n",
      "Epoch 3/10\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.1810 - val_loss: 0.3245\n",
      "Epoch 4/10\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.1758 - val_loss: 0.3138\n",
      "Epoch 5/10\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.1702 - val_loss: 0.3190\n",
      "Epoch 6/10\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.1678 - val_loss: 0.3103\n",
      "Epoch 7/10\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.1662 - val_loss: 0.3119\n",
      "Epoch 8/10\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.1641 - val_loss: 0.3089\n",
      "Epoch 9/10\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.1627 - val_loss: 0.3115\n",
      "Epoch 10/10\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.1621 - val_loss: 0.3126\n",
      "(23133, 30, 10)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 30, 10)            21        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 11, 10)            2010      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1, 10)             1110      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 44        \n",
      "=================================================================\n",
      "Total params: 3,185\n",
      "Trainable params: 3,164\n",
      "Non-trainable params: 21\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.3077 - val_loss: 0.3424\n",
      "Epoch 2/10\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.1799 - val_loss: 0.2955\n",
      "Epoch 3/10\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.1690 - val_loss: 0.3095\n",
      "Epoch 4/10\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.1648 - val_loss: 0.3045\n",
      "Epoch 5/10\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.1620 - val_loss: 0.3067\n",
      "Epoch 6/10\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.1591 - val_loss: 0.2877\n",
      "Epoch 7/10\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.1580 - val_loss: 0.2886\n",
      "Epoch 8/10\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.1565 - val_loss: 0.2900\n",
      "Epoch 9/10\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.1559 - val_loss: 0.2918\n",
      "Epoch 10/10\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 0.1543 - val_loss: 0.2866\n",
      "(22790, 30, 10)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 30, 10)            21        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 11, 10)            2010      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1, 10)             1110      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 44        \n",
      "=================================================================\n",
      "Total params: 3,185\n",
      "Trainable params: 3,164\n",
      "Non-trainable params: 21\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.2917 - val_loss: 0.3375\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1771 - val_loss: 0.3227\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1661 - val_loss: 0.3204\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1611 - val_loss: 0.3256\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1569 - val_loss: 0.3185\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1550 - val_loss: 0.3136\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1523 - val_loss: 0.3307\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1510 - val_loss: 0.3276\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1500 - val_loss: 0.3190\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1492 - val_loss: 0.3303\n",
      "(21630, 30, 10)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 30, 10)            21        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 11, 10)            2010      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1, 10)             1110      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 44        \n",
      "=================================================================\n",
      "Total params: 3,185\n",
      "Trainable params: 3,164\n",
      "Non-trainable params: 21\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 0.3037 - val_loss: 0.4372\n",
      "Epoch 2/10\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.1895 - val_loss: 0.4302\n",
      "Epoch 3/10\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.1776 - val_loss: 0.4345\n",
      "Epoch 4/10\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.1729 - val_loss: 0.4296\n",
      "Epoch 5/10\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.1707 - val_loss: 0.4336\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 2ms/step - loss: 0.1690 - val_loss: 0.4281\n",
      "Epoch 7/10\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.1675 - val_loss: 0.4216\n",
      "Epoch 8/10\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.1672 - val_loss: 0.4371\n",
      "Epoch 9/10\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.1658 - val_loss: 0.4173\n",
      "Epoch 10/10\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.1645 - val_loss: 0.4264\n",
      "(22833, 30, 10)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization (Normalization (None, 30, 10)            21        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 11, 10)            2010      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1, 10)             1110      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 44        \n",
      "=================================================================\n",
      "Total params: 3,185\n",
      "Trainable params: 3,164\n",
      "Non-trainable params: 21\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 0s 3ms/step - loss: 0.3050 - val_loss: 0.2461\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1903 - val_loss: 0.2026\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1797 - val_loss: 0.1975\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1751 - val_loss: 0.1770\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1716 - val_loss: 0.1803\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1683 - val_loss: 0.1765\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1656 - val_loss: 0.1911\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1643 - val_loss: 0.1757\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1626 - val_loss: 0.1624\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1622 - val_loss: 0.1679\n"
     ]
    }
   ],
   "source": [
    "trial_results, average_results = train_models(hyperparam_space['model'], hyperparameter_configs, data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_size</th>\n",
       "      <th>model_type</th>\n",
       "      <th>cnn_kernel_size</th>\n",
       "      <th>cnn_activation</th>\n",
       "      <th>dense_activation</th>\n",
       "      <th>optim_loss</th>\n",
       "      <th>optim_optimizer</th>\n",
       "      <th>training_epochs</th>\n",
       "      <th>training_batch_size</th>\n",
       "      <th>left_rmse_mean</th>\n",
       "      <th>right_rmse_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>cnn</td>\n",
       "      <td>20</td>\n",
       "      <td>relu</td>\n",
       "      <td>tanh</td>\n",
       "      <td>mean_absolute_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>11.792042</td>\n",
       "      <td>8.927512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   window_size model_type  cnn_kernel_size cnn_activation dense_activation  \\\n",
       "0           30        cnn               20           relu             tanh   \n",
       "\n",
       "            optim_loss optim_optimizer  training_epochs  training_batch_size  \\\n",
       "0  mean_absolute_error            adam               10                  128   \n",
       "\n",
       "   left_rmse_mean  right_rmse_mean  \n",
       "0       11.792042         8.927512  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(average_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSTM Model\n",
    "# hyperparam_space = {\n",
    "#     'window_size': [20],\n",
    "#     'model': 'lstm',\n",
    "#     'lstm': {\n",
    "#       'units': [30],\n",
    "#       'activation': ['relu']\n",
    "#     },\n",
    "#     'dense': {\n",
    "#         'activation': ['tanh']\n",
    "#     },\n",
    "#     'optimizer': {\n",
    "#         'loss': ['mean_absolute_error'],\n",
    "#         'optimizer': ['adam']\n",
    "#     },\n",
    "#     'training': {\n",
    "#         'epochs': [10],\n",
    "#         'batch_size': [128]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "## CNN Model\n",
    "# hyperparam_space = {\n",
    "#     'window_size': [20],\n",
    "#     'model': 'cnn',\n",
    "#     'cnn': {\n",
    "#       'kernel_size': [10],\n",
    "#       'activation': ['relu']\n",
    "#     },\n",
    "#     'dense': {\n",
    "#         'activation': ['tanh']\n",
    "#     },\n",
    "#     'optimizer': {\n",
    "#         'loss': ['mean_absolute_error'],\n",
    "#         'optimizer': ['adam']\n",
    "#     },\n",
    "#     'training': {\n",
    "#         'epochs': [10],\n",
    "#         'batch_size': [128]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "## MLP Model\n",
    "# hyperparam_space = {\n",
    "#     'window_size': [20],\n",
    "#     'model': 'mlp',\n",
    "#     'dense': {\n",
    "#         'num_layers': [10, 20],\n",
    "#         'num_nodes': [5, 10],\n",
    "#         'activation': ['tanh']\n",
    "#     },\n",
    "#     'optimizer': {\n",
    "#         'loss': ['mean_absolute_error'],\n",
    "#         'optimizer': ['adam']\n",
    "#     },\n",
    "#     'training': {\n",
    "#         'epochs': [10],\n",
    "#         'batch_size': [128]\n",
    "#     }\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
